{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano implementation of HMM algorithms\n",
    "\n",
    "This notebook implements some of the HMM algorithms using Theano. These may be helpful for incorporating them in the graphs of some other models in Theano. These are implemented in the same manner as in the other notebook about HMMs.\n",
    "\n",
    "## Discrete HMM\n",
    "\n",
    "We start with a toy HMM example from [Rabiner's](http://www.ee.columbia.edu/~dpwe/e6820/papers/Rabiner89-hmm.pdf) paper.\n",
    "\n",
    "Many improvements can be added to this (and may be added in the future):\n",
    "  \n",
    "  * everything should be moved to the log-domain - for computation stability. This is especially important for GPUs which usually have a lower floating-point precision. This example here works only for the smallest examples (a few observations).\n",
    "  \n",
    "  * continous density models - this discrete example cannot be applied to most practical examples.\n",
    "  \n",
    "  * custom topologies - this is a simple ergodic example. In practice, we'd want to be able to design a specific transition graph for a particular use.\n",
    "  \n",
    "  * combining models - real applications rely on being able to combine several models to be able to train them for specific problems. E.g. combining many tri-phone models for speech recognition. This should also include the ability to do state-tying.\n",
    "  \n",
    "  * better training algorithms - only Baum-Welch and the simplest gradient descent are demonstrated here. There are other methods that oculd work better/faster.\n",
    "  \n",
    "The example below will demonstrate the code using a similar notation and equations from Rabiner's paper. First we import the required stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN (CNMeM is enabled)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.ifelse import ifelse\n",
    "import pickle\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HMM class code\n",
    "\n",
    "Here we create the HMM class. Everything is compiled in the constructor. We also provide methods for all the individual algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DiscreteHMM:\n",
    "    \n",
    "    def __init__(self, N=3, M=4):        \n",
    "        \n",
    "        updates={}\n",
    "                \n",
    "        pi = theano.shared((np.ones(N)/N).astype(theano.config.floatX))\n",
    "        a = theano.shared((np.ones((N,N))/(N*np.ones(N))).astype(theano.config.floatX))\n",
    "        b = theano.shared((np.ones((N,M))/(N*np.ones(M))).astype(theano.config.floatX))\n",
    "        N = theano.shared(N)\n",
    "        M = theano.shared(M)\n",
    "        \n",
    "        self.pi=pi\n",
    "        self.a=a\n",
    "        self.b=b\n",
    "        self.N=N\n",
    "        self.M=M\n",
    "        \n",
    "        O = T.ivector()\n",
    "        TT = O.shape[0]\n",
    "        \n",
    "        \n",
    "        #forward algorithm:\n",
    "        \n",
    "        alpha0=pi*b[:,O[0]]\n",
    "        \n",
    "        alpha_scan,upd = theano.scan(fn=lambda O,alpha_p: T.dot(alpha_p,a)*b[:,O],\n",
    "                               sequences=O[1:],\n",
    "                               outputs_info=alpha0)\n",
    "        \n",
    "        updates.update(upd)\n",
    "        \n",
    "        alpha=T.concatenate((alpha0.reshape((1,N)),alpha_scan))                \n",
    "        \n",
    "        #backward algorithm:\n",
    "        \n",
    "        beta0=T.ones(N).astype(theano.config.floatX)\n",
    "        \n",
    "        beta_scan,upd = theano.scan(fn=lambda O,beta_p: T.dot(beta_p*b[:,O],a.T),\n",
    "                               sequences=O[1:],\n",
    "                               outputs_info=beta0,\n",
    "                               go_backwards=True)\n",
    "        updates.update(upd)\n",
    "        \n",
    "        beta=T.concatenate((beta_scan[::-1],beta0.reshape((1,N))))        \n",
    "        \n",
    "        #full model probability:\n",
    "        \n",
    "        full_prob = alpha_scan[-1].sum()        \n",
    "        \n",
    "        #forward-backward probabilities:\n",
    "        \n",
    "        gamma=alpha*beta/full_prob        \n",
    "        \n",
    "        #viterbi algorithm:\n",
    "        \n",
    "        def viterbi_rec_step(O, delta_p, phi_p):\n",
    "            m=delta_p*a.T\n",
    "            phi=m.argmax(axis=1)\n",
    "            delta=m[T.arange(N),phi]*b[:,O]\n",
    "            return delta,phi\n",
    "        \n",
    "        phi0=T.zeros(N).astype('int64')\n",
    "\n",
    "        [delta_scan, phi_scan], upd = theano.scan(fn=viterbi_rec_step,\n",
    "                                                  sequences=O[1:],\n",
    "                                                  outputs_info=[alpha0,phi0])        \n",
    "        \n",
    "        updates.update(upd)\n",
    "        \n",
    "        QT=phi_scan[-1].argmax()        \n",
    "        vite_prob = delta_scan[-1,QT]\n",
    "        \n",
    "        Q_scan, upd = theano.scan(fn=lambda phi, Q: phi[Q],\n",
    "                             sequences=phi_scan,\n",
    "                             outputs_info=QT,\n",
    "                             go_backwards=True)\n",
    "        \n",
    "        updates.update(upd)\n",
    "                                                  \n",
    "        Q=T.concatenate((Q_scan[::-1],QT.reshape((1,))))\n",
    "        \n",
    "        #transition probabilities\n",
    "        \n",
    "        xi=alpha[:-1].reshape((TT-1,N,1))*a.reshape((1,N,N))*b[:,O[1:]].T.reshape((TT-1,1,N))*beta[1:].reshape((TT-1,1,N))/full_prob\n",
    "        \n",
    "        #expected values\n",
    "        \n",
    "        exp_pi=gamma[0]\n",
    "        \n",
    "        exp_a=xi.sum(axis=0)/gamma[:-1].sum(axis=0).reshape((N,1))\n",
    "        \n",
    "        exp_b_map, upd = theano.map(fn=lambda k: T.sum(gamma[T.eq(O,k).nonzero()],axis=0)/T.sum(gamma,axis=0), \n",
    "                         sequences=T.arange(M))\n",
    "        \n",
    "        updates.update(upd)\n",
    "        \n",
    "        exp_b = exp_b_map.T\n",
    "        \n",
    "        exp_err = T.concatenate(((pi-exp_pi).ravel(),(a-exp_a).ravel(),(b-exp_b).ravel()))\n",
    "        \n",
    "        exp_mean_err = T.mean(exp_err**2)\n",
    "        \n",
    "        #Baum-Welch updates:\n",
    "        \n",
    "        baum_welch_updates=OrderedDict()\n",
    "        exp_updates={pi:exp_pi,a:exp_a,b:exp_b}\n",
    "        baum_welch_updates.update(updates)\n",
    "        baum_welch_updates.update(exp_updates)\n",
    "        \n",
    "        #Gradient descent:\n",
    "        \n",
    "        pi_grad=T.grad(cost=full_prob,wrt=pi)\n",
    "        a_grad=T.grad(cost=full_prob,wrt=a)\n",
    "        b_grad=T.grad(cost=full_prob,wrt=b)\n",
    "                \n",
    "        lr=T.scalar()\n",
    "        \n",
    "        pi_upd=pi*(pi_grad**lr)\n",
    "        norm_pi_upd=pi_upd/pi_upd.sum()\n",
    "        \n",
    "        a_upd=a*(a_grad**lr)\n",
    "        norm_a_upd=(a_upd.T/a_upd.sum(axis=1)).T\n",
    "        \n",
    "        b_upd=b*(b_grad**lr)\n",
    "        norm_b_upd=b_upd/b_upd.sum(axis=0)\n",
    "        \n",
    "        gd_updates=OrderedDict()\n",
    "        grad_updates={pi:norm_pi_upd,\n",
    "                      a:norm_a_upd,\n",
    "                      b:norm_b_upd}\n",
    "        gd_updates.update(updates)\n",
    "        gd_updates.update(grad_updates)            \n",
    "        \n",
    "        #function definitions\n",
    "        \n",
    "        self.forward_fun = theano.function(inputs=[O], outputs=alpha, updates=updates)\n",
    "        \n",
    "        self.backward_fun = theano.function(inputs=[O], outputs=beta, updates=updates)\n",
    "        \n",
    "        self.full_prob_fun = theano.function(inputs=[O], outputs=full_prob, updates=updates)\n",
    "        \n",
    "        self.gamma_fun = theano.function(inputs=[O], outputs=gamma, updates=updates)\n",
    "        \n",
    "        self.viterbi_fun = theano.function(inputs=[O], outputs=[Q,vite_prob], updates=updates)\n",
    "    \n",
    "        self.xi_fun = theano.function(inputs=[O], outputs=xi, updates=updates)            \n",
    "        \n",
    "        self.exp_fun = theano.function(inputs=[O], outputs=[exp_pi,exp_a,exp_b], updates=updates)\n",
    "        \n",
    "        self.baum_welch_fun = theano.function(inputs=[O], outputs=[full_prob,exp_mean_err], updates=baum_welch_updates)\n",
    "        \n",
    "        self.gd_fun = theano.function(inputs=[O,lr], outputs=full_prob, updates=gd_updates)        \n",
    "    \n",
    "    def setModel(self,pi,a,b,N,M):\n",
    "        \n",
    "        self.pi.set_value(pi.astype(theano.config.floatX))\n",
    "        self.a.set_value(a.astype(theano.config.floatX))\n",
    "        self.b.set_value(b.astype(theano.config.floatX))\n",
    "        self.N.set_value(N)\n",
    "        self.M.set_value(M)\n",
    "        \n",
    "    def getModel(self):\n",
    "        \n",
    "        return self.pi.get_value(),self.a.get_value(),self.b.get_value(),self.N.get_value(),self.M.get_value()\n",
    "    \n",
    "    def forward(self, O):\n",
    "        \n",
    "        return self.forward_fun(O.astype('int32')) \n",
    "    \n",
    "    \n",
    "    def backward(self, O):\n",
    "        \n",
    "        return self.backward_fun(O.astype('int32'))        \n",
    "    \n",
    "    def full_prob(self, O):\n",
    "        \n",
    "        return self.full_prob_fun(O.astype('int32'))\n",
    "    \n",
    "    def gamma(self, O):\n",
    "        \n",
    "        return self.gamma_fun(O.astype('int32'))\n",
    "    \n",
    "    def viterbi(self, O):\n",
    "        \n",
    "        return self.viterbi_fun(O.astype('int32'))\n",
    "    \n",
    "    def xi(self, O):\n",
    "        \n",
    "        return self.xi_fun(O.astype('int32'))\n",
    "    \n",
    "    def exp_values(self, O):\n",
    "        \n",
    "        return self.exp_fun(O.astype('int32'))\n",
    "    \n",
    "    def baum_welch(self,O):\n",
    "        \n",
    "        return self.baum_welch_fun(O.astype('int32'))\n",
    "    \n",
    "    def gradient_descent(self,O,lr=0.01):\n",
    "        \n",
    "        return self.gd_fun(O.astype('int32'),lr)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation\n",
    "\n",
    "We can either use the default (all equally probable) or some other random values to begin with. Here we will read the model parameters from a file created in my other notebook. It will allow us to make sure all the calculations match the ones there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 3\n",
      "Number of observation classes: 4\n",
      "Number of time steps: 5\n",
      "Observation sequence: [0 1 2 1 0]\n",
      "Priors: [ 0.13060479  0.574861    0.29453421]\n",
      "Transition matrix:\n",
      "[[ 0.44056368  0.08175695  0.47767937]\n",
      " [ 0.4364632   0.40292622  0.16061058]\n",
      " [ 0.00281623  0.88340507  0.1137787 ]]\n",
      "Observation probability matrix:\n",
      "[[ 0.53375578  0.10345127  0.33152859  0.66017725]\n",
      " [ 0.26331038  0.65987904  0.40656356  0.11079022]\n",
      " [ 0.20293384  0.23666969  0.26190785  0.22903253]]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/hmm.pkl') as f:\n",
    "    O,pi,a,b,N,M,Time=pickle.load(f)\n",
    "    \n",
    "print 'Number of states: {}'.format(N)\n",
    "print 'Number of observation classes: {}'.format(M)\n",
    "print 'Number of time steps: {}'.format(Time) #T is taken by theano.tensor\n",
    "print 'Observation sequence: {}'.format(O)\n",
    "print 'Priors: {}'.format(pi)\n",
    "print 'Transition matrix:\\n{}'.format(a)\n",
    "print 'Observation probability matrix:\\n{}'.format(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will contruct the HMM object. The constructor needs to compile everything and since we have a few functions, it may take a little while:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 272 ms, total: 21.2 s\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%time hmm=DiscreteHMM()\n",
    "\n",
    "#we can also set the model parameters\n",
    "hmm.setModel(pi,a,b,N,M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "\n",
    "Let's test the methots now. You can compare the values with the ones from my other notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward probabilities:\n",
      "[[ 0.06971106  0.15136686  0.05977096]\n",
      " [ 0.01002924  0.07884961  0.01524421]\n",
      " [ 0.01288864  0.01872524  0.00502583]\n",
      " [ 0.00143438  0.00860381  0.0023042 ]\n",
      " [ 0.00234515  0.00147968  0.00047267]]\n",
      "Backward probabilities:\n",
      "[[ 0.00983429  0.01427416  0.02428114]\n",
      " [ 0.04165408  0.03925478  0.05146331]\n",
      " [ 0.06524467  0.12455948  0.22368039]\n",
      " [ 0.35361814  0.37165272  0.25720245]\n",
      " [ 1.          1.          1.        ]]\n",
      "Full model probability: 0.0042975009419\n",
      "Complete state probability:\n",
      "[[ 0.15952496  0.50276548  0.33770952]\n",
      " [ 0.09720974  0.72023821  0.18255197]\n",
      " [ 0.19567539  0.5427354   0.2615892 ]\n",
      " [ 0.11802761  0.74406749  0.1379049 ]\n",
      " [ 0.54570061  0.34431106  0.10998834]]\n",
      "Viterbi sequence: [1 1 1 1 0] its probability 0.000408370891819\n",
      "State transition probability:\n",
      "[[[  3.07955407e-02   3.43532078e-02   9.43762064e-02]\n",
      "  [  6.62454143e-02   3.67618442e-01   6.89015985e-02]\n",
      "  [  1.68785889e-04   3.18266600e-01   1.92741621e-02]]\n",
      "\n",
      " [[  2.22395975e-02   9.66233574e-03   6.53078109e-02]\n",
      "  [  1.73219696e-01   3.74381483e-01   1.72637105e-01]\n",
      "  [  2.16084343e-04   1.58691600e-01   2.36442853e-02]]\n",
      "\n",
      " [[  4.83359434e-02   6.01336285e-02   8.72057900e-02]\n",
      "  [  6.95711821e-02   4.30564851e-01   4.25993763e-02]\n",
      "  [  1.20484372e-04   2.53368974e-01   8.09973013e-03]]\n",
      "\n",
      " [[  7.84874782e-02   7.18524726e-03   3.23548988e-02]\n",
      "  [  4.66407150e-01   2.12406844e-01   6.52534664e-02]\n",
      "  [  8.05964053e-04   1.24718964e-01   1.23799816e-02]]]\n"
     ]
    }
   ],
   "source": [
    "print 'Forward probabilities:\\n{}'.format(hmm.forward(O))\n",
    "print 'Backward probabilities:\\n{}'.format(hmm.backward(O))\n",
    "print 'Full model probability: {}'.format(hmm.full_prob(O))\n",
    "print 'Complete state probability:\\n{}'.format(hmm.gamma(O))\n",
    "seq,vite_prob=hmm.viterbi(O)\n",
    "print 'Viterbi sequence: {} its probability {}'.format(seq,vite_prob)\n",
    "print 'State transition probability:\\n{}'.format(hmm.xi(O))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected priors: [ 0.15952496  0.50276548  0.33770952]\n",
      "Expected transitions:\n",
      "[[ 0.31529921  0.19517367  0.48952708]\n",
      " [ 0.30896547  0.55182409  0.13921055]\n",
      " [ 0.00142573  0.929645    0.06892936]]\n",
      "Expected observations:\n",
      "[[ 0.63184422  0.1928411   0.17531464  0.        ]\n",
      " [ 0.29679105  0.5130502   0.19015874  0.        ]\n",
      " [ 0.4347662   0.31120053  0.25403327  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "exp_pi,exp_a,exp_b=hmm.exp_values(O)\n",
    "print 'Expected priors: {}'.format(exp_pi)\n",
    "print 'Expected transitions:\\n{}'.format(exp_a)\n",
    "print 'Expected observations:\\n{}'.format(exp_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baum-Welch\n",
    "\n",
    "We will run 15 iterations of the Baum-Welch EM reestimation here. We will also output the model probability (which should increase with each iteration) and also the mean difference between the model parameters and their expected values (which will decrease to 0 as the model converges on the optimum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 P=0.0042975009419 delta_exp=0.0312950722873\n",
      "Iteration #2 P=0.00509988935664 delta_exp=0.00250484491698\n",
      "Iteration #3 P=0.00619259942323 delta_exp=0.00354749825783\n",
      "Iteration #4 P=0.00862175133079 delta_exp=0.00476954458281\n",
      "Iteration #5 P=0.0136389173567 delta_exp=0.00249158055522\n",
      "Iteration #6 P=0.0189215112478 delta_exp=0.00156689342111\n",
      "Iteration #7 P=0.0234132837504 delta_exp=0.00485259993002\n",
      "Iteration #8 P=0.0374571271241 delta_exp=0.00896292272955\n",
      "Iteration #9 P=0.109155744314 delta_exp=0.00389885343611\n",
      "Iteration #10 P=0.218594044447 delta_exp=0.000297478662105\n",
      "Iteration #11 P=0.238835394382 delta_exp=7.89283149061e-05\n",
      "Iteration #12 P=0.244890481234 delta_exp=1.83135434781e-05\n",
      "Iteration #13 P=0.247751742601 delta_exp=3.72286672246e-06\n",
      "Iteration #14 P=0.24902997911 delta_exp=7.08700042651e-07\n",
      "Iteration #15 P=0.249585151672 delta_exp=1.30926537167e-07\n"
     ]
    }
   ],
   "source": [
    "hmm.setModel(pi,a,b,N,M)\n",
    "for i in range(15):    \n",
    "    prob,exp_err=hmm.baum_welch(O)\n",
    "    print 'Iteration #{} P={} delta_exp={}'.format(i+1,prob,exp_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "Since this is Theano, we can easily implement GD using the built-in *grad* method. The parameters are updated by multiplying them with their gradients. The updated values have to also be renormalized to keep the stochasticity of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 P=0.0042975009419\n",
      "Iteration #2 P=0.0051160780713\n",
      "Iteration #3 P=0.00623863283545\n",
      "Iteration #4 P=0.0079468395561\n",
      "Iteration #5 P=0.0107951052487\n",
      "Iteration #6 P=0.0159269031137\n",
      "Iteration #7 P=0.0257520414889\n",
      "Iteration #8 P=0.0452238433063\n",
      "Iteration #9 P=0.0835462510586\n",
      "Iteration #10 P=0.154380306602\n",
      "Iteration #11 P=0.270117342472\n",
      "Iteration #12 P=0.428860872984\n",
      "Iteration #13 P=0.605754315853\n",
      "Iteration #14 P=0.764089465141\n",
      "Iteration #15 P=0.87856990099\n",
      "Iteration #16 P=0.946424365044\n",
      "Iteration #17 P=0.979877769947\n",
      "Iteration #18 P=0.993670403957\n",
      "Iteration #19 P=0.998380482197\n",
      "Iteration #20 P=0.999676942825\n",
      "0.999952375889\n",
      "PI: [ 0.00000006  0.99997818  0.00002175]\n",
      "A:\n",
      "[[ 0.          0.99999964  0.00000029]\n",
      " [ 0.00000001  0.99999952  0.00000041]\n",
      " [ 0.          1.          0.        ]]\n",
      "B:\n",
      "[[ 0.00000005  0.          0.00000001         nan]\n",
      " [ 0.99998808  1.          0.99999994         nan]\n",
      " [ 0.00001184  0.00000004  0.00000008         nan]]\n"
     ]
    }
   ],
   "source": [
    "hmm.setModel(pi,a,b,N,M)\n",
    "\n",
    "for i in range(20):\n",
    "    prob=hmm.gradient_descent(O,0.2)\n",
    "    print 'Iteration #{} P={}'.format(i+1,prob)\n",
    "\n",
    "print hmm.full_prob(O)\n",
    "\n",
    "pi_n,a_n,b_n,N_n,M_n=hmm.getModel()\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print 'PI: {}'.format(pi_n)\n",
    "print 'A:\\n{}'.format(a_n)\n",
    "print 'B:\\n{}'.format(b_n)\n",
    "np.set_printoptions(suppress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method quickly converges to the optimum, although in this example the optimum is not a very useful model because it stays mostly in one state all the time. Having several different sequences would probably serve as a better test for this method..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log model\n",
    "\n",
    "This is the same class above, but moved into the log domain. All the paramaters and calculations are done in the log domain.\n",
    "\n",
    "Some log arithmetic hints can be found [here](https://github.com/UFAL-DSG/alex/blob/master/alex/ml/logarithmetic.py).\n",
    "\n",
    "In log domain, things like multiplication and division are trivial, but simple addition, subtraction and sum become a nuisance. That is why they need to be reimplemented by pulling the values back into the normal linear domain and then taking them back after the operation is completed. So add becomes LogAddExp and sum becomes LogSumExp and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylearn2.expr.basic import log_sum_exp\n",
    "\n",
    "\n",
    "def LogDot(a,b):\n",
    "    return log_sum_exp(a + b.T, axis=1)\n",
    "\n",
    "def LogSum(a,axis=None):\n",
    "    return log_sum_exp(a,axis)\n",
    "\n",
    "def LogAdd(a,b):\n",
    "    return T.log(T.exp(a)+T.exp(b))\n",
    "\n",
    "def LogSub(a,b):\n",
    "    return T.log(T.exp(a)-T.exp(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the actual class in the LogDomain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LogDiscreteHMM:\n",
    "    \n",
    "    def __init__(self, N=3, M=4):        \n",
    "        \n",
    "        updates={}\n",
    "                \n",
    "        pi = theano.shared((np.zeros(N)/N).astype(theano.config.floatX))\n",
    "        a = theano.shared((np.zeros((N,N))/(N*np.ones(N))).astype(theano.config.floatX))\n",
    "        b = theano.shared((np.zeros((N,M))/(N*np.ones(M))).astype(theano.config.floatX))\n",
    "        N = theano.shared(N)\n",
    "        M = theano.shared(M)\n",
    "        \n",
    "        self.pi=pi\n",
    "        self.a=a\n",
    "        self.b=b\n",
    "        self.N=N\n",
    "        self.M=M\n",
    "        \n",
    "        O = T.ivector()\n",
    "        TT = O.shape[0]\n",
    "        \n",
    "        \n",
    "        #forward algorithm:\n",
    "        \n",
    "        alpha0=pi+b[:,O[0]]\n",
    "        \n",
    "        alpha_scan,upd = theano.scan(fn=lambda O,alpha_p: LogDot(alpha_p,a)+b[:,O],\n",
    "                               sequences=O[1:],\n",
    "                               outputs_info=alpha0)\n",
    "        \n",
    "        updates.update(upd)\n",
    "        \n",
    "        alpha=T.concatenate((alpha0.reshape((1,N)),alpha_scan))                \n",
    "        \n",
    "        #backward algorithm:\n",
    "        \n",
    "        beta0=T.zeros(N).astype(theano.config.floatX)\n",
    "        \n",
    "        beta_scan,upd = theano.scan(fn=lambda O,beta_p: LogDot(beta_p+b[:,O],a.T),\n",
    "                               sequences=O[1:],\n",
    "                               outputs_info=beta0,\n",
    "                               go_backwards=True)\n",
    "        updates.update(upd)\n",
    "        \n",
    "        beta=T.concatenate((beta_scan[::-1],beta0.reshape((1,N))))        \n",
    "        \n",
    "        #full model probability:\n",
    "        \n",
    "        full_prob = LogSum(alpha_scan[-1])\n",
    "        \n",
    "        #forward-backward probabilities:\n",
    "        \n",
    "        gamma=alpha+beta-full_prob        \n",
    "        \n",
    "        #viterbi algorithm:\n",
    "        \n",
    "        def viterbi_rec_step(O, delta_p, phi_p):\n",
    "            m=delta_p+a.T\n",
    "            phi=m.argmax(axis=1)\n",
    "            delta=m[T.arange(N),phi]+b[:,O]\n",
    "            return delta,phi\n",
    "        \n",
    "        phi0=T.zeros(N).astype('int64')\n",
    "\n",
    "        [delta_scan, phi_scan], upd = theano.scan(fn=viterbi_rec_step,\n",
    "                                                  sequences=O[1:],\n",
    "                                                  outputs_info=[alpha0,phi0])        \n",
    "        \n",
    "        updates.update(upd)\n",
    "        \n",
    "        QT=phi_scan[-1].argmax()        \n",
    "        vite_prob = delta_scan[-1,QT]\n",
    "        \n",
    "        Q_scan, upd = theano.scan(fn=lambda phi, Q: phi[Q],\n",
    "                             sequences=phi_scan,\n",
    "                             outputs_info=QT,\n",
    "                             go_backwards=True)\n",
    "        \n",
    "        updates.update(upd)\n",
    "                                                  \n",
    "        Q=T.concatenate((Q_scan[::-1],QT.reshape((1,))))\n",
    "        \n",
    "        #transition probabilities\n",
    "        \n",
    "        xi=alpha[:-1].reshape((TT-1,N,1))+a.reshape((1,N,N))+b[:,O[1:]].T.reshape((TT-1,1,N))+beta[1:].reshape((TT-1,1,N))-full_prob\n",
    "        \n",
    "        #expected values\n",
    "        \n",
    "        exp_pi=gamma[0]\n",
    "        \n",
    "        exp_a=LogSum(xi,axis=0)-LogSum(gamma[:-1],axis=0).reshape((N,1))\n",
    "        \n",
    "        def exp_b_fun(k):\n",
    "            return ifelse(T.eq(gamma[T.eq(O,k).nonzero()].shape[0],0),\n",
    "                          T.ones((a.shape[1],))*(-99),\n",
    "                          LogSum(gamma[T.eq(O,k).nonzero()],axis=0)-LogSum(gamma,axis=0))\n",
    "        \n",
    "        exp_b_map, upd = theano.map(fn=exp_b_fun, sequences=T.arange(M))\n",
    "        \n",
    "        updates.update(upd)\n",
    "        \n",
    "        exp_b = exp_b_map.T\n",
    "        \n",
    "        exp_err = T.concatenate(((np.exp(pi)-np.exp(exp_pi)).ravel(),\n",
    "                                 (np.exp(a)-np.exp(exp_a)).ravel(),\n",
    "                                 (np.exp(b)-np.exp(exp_b)).ravel()))\n",
    "        \n",
    "        exp_mean_err = T.mean(exp_err**2)\n",
    "        \n",
    "        #Baum-Welch updates:\n",
    "        \n",
    "        baum_welch_updates=OrderedDict()\n",
    "        exp_updates={pi:exp_pi,a:exp_a,b:exp_b}\n",
    "        baum_welch_updates.update(updates)\n",
    "        baum_welch_updates.update(exp_updates)\n",
    "        \n",
    "        #Gradient descent:\n",
    "        \n",
    "        pi_grad=T.grad(cost=full_prob,wrt=pi)\n",
    "        a_grad=T.grad(cost=full_prob,wrt=a)\n",
    "        b_grad=T.grad(cost=full_prob,wrt=b)\n",
    "                \n",
    "        lr=T.scalar()\n",
    "        \n",
    "        pi_upd=pi+(pi_grad*lr)\n",
    "        norm_pi_upd=pi_upd-LogSum(pi_upd)\n",
    "        \n",
    "        a_upd=a+(a_grad*lr)\n",
    "        norm_a_upd=(a_upd.T-LogSum(a_upd,axis=1)).T\n",
    "        \n",
    "        b_upd=b+(b_grad*lr)\n",
    "        norm_b_upd=b_upd-LogSum(b_upd,axis=0)\n",
    "        \n",
    "        gd_updates=OrderedDict()\n",
    "        grad_updates={pi:norm_pi_upd,\n",
    "                      a:norm_a_upd,\n",
    "                      b:norm_b_upd}\n",
    "        gd_updates.update(updates)\n",
    "        gd_updates.update(grad_updates)            \n",
    "        \n",
    "        #function definitions\n",
    "        \n",
    "        self.forward_fun = theano.function(inputs=[O], outputs=alpha, updates=updates)\n",
    "        \n",
    "        self.backward_fun = theano.function(inputs=[O], outputs=beta, updates=updates)\n",
    "        \n",
    "        self.full_prob_fun = theano.function(inputs=[O], outputs=full_prob, updates=updates)\n",
    "        \n",
    "        self.gamma_fun = theano.function(inputs=[O], outputs=gamma, updates=updates)\n",
    "        \n",
    "        self.viterbi_fun = theano.function(inputs=[O], outputs=[Q,vite_prob], updates=updates)\n",
    "    \n",
    "        self.xi_fun = theano.function(inputs=[O], outputs=xi, updates=updates)          \n",
    "        \n",
    "        self.exp_fun = theano.function(inputs=[O], outputs=[exp_pi,exp_a,exp_b], updates=updates)\n",
    "        \n",
    "        self.baum_welch_fun = theano.function(inputs=[O], outputs=[full_prob,exp_mean_err], updates=baum_welch_updates)\n",
    "        \n",
    "        self.gd_fun = theano.function(inputs=[O,lr], outputs=full_prob, updates=gd_updates)\n",
    "    \n",
    "    def setModel(self,pi,a,b,N,M):\n",
    "        \n",
    "        self.pi.set_value(pi.astype(theano.config.floatX))\n",
    "        self.a.set_value(a.astype(theano.config.floatX))\n",
    "        self.b.set_value(b.astype(theano.config.floatX))\n",
    "        self.N.set_value(N)\n",
    "        self.M.set_value(M)\n",
    "    \n",
    "    def getModel(self):\n",
    "        \n",
    "        return self.pi.get_value(),self.a.get_value(),self.b.get_value(),self.N.get_value(),self.M.get_value()\n",
    "    \n",
    "    \n",
    "    def forward(self, O):\n",
    "        \n",
    "        return self.forward_fun(O.astype('int32')) \n",
    "    \n",
    "    \n",
    "    def backward(self, O):\n",
    "        \n",
    "        return self.backward_fun(O.astype('int32'))        \n",
    "    \n",
    "    def full_prob(self, O):\n",
    "        \n",
    "        return self.full_prob_fun(O.astype('int32'))\n",
    "    \n",
    "    def gamma(self, O):\n",
    "        \n",
    "        return self.gamma_fun(O.astype('int32'))\n",
    "    \n",
    "    def viterbi(self, O):\n",
    "        \n",
    "        return self.viterbi_fun(O.astype('int32'))\n",
    "    \n",
    "    def xi(self, O):\n",
    "        \n",
    "        return self.xi_fun(O.astype('int32'))\n",
    "    \n",
    "    def exp_values(self, O):\n",
    "        \n",
    "        return self.exp_fun(O.astype('int32'))\n",
    "    \n",
    "    def baum_welch(self,O):\n",
    "        \n",
    "        return self.baum_welch_fun(O.astype('int32'))\n",
    "    \n",
    "    def gradient_descent(self,O,lr=0.01):\n",
    "        \n",
    "        return self.gd_fun(O.astype('int32'),lr)        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we construct the object. It is not much more complicated than the one above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 232 ms, total: 23.5 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%time loghmm=LogDiscreteHMM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all the parameters are in the log domain, we have to take logarithms of all the values that were used above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loghmm.setModel(np.log(pi),np.log(a),np.log(b),N,M) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we have to compute the exponential of the results to get back into the normal domain. Nevertheless, the results are the same as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward probabilities:\n",
      "[[ 0.06971105  0.15136687  0.05977095]\n",
      " [ 0.01002924  0.07884961  0.01524421]\n",
      " [ 0.01288864  0.01872524  0.00502583]\n",
      " [ 0.00143438  0.00860382  0.0023042 ]\n",
      " [ 0.00234515  0.00147968  0.00047268]]\n",
      "Backward probabilities:\n",
      "[[ 0.00983429  0.01427416  0.02428114]\n",
      " [ 0.04165408  0.03925479  0.0514633 ]\n",
      " [ 0.06524467  0.12455946  0.22368038]\n",
      " [ 0.35361817  0.37165272  0.25720248]\n",
      " [ 1.          1.          1.        ]]\n",
      "Full model probability: 0.00429750420153\n",
      "Complete state probability:\n",
      "[[ 0.15952486  0.50276518  0.33770928]\n",
      " [ 0.09720964  0.72023761  0.1825518 ]\n",
      " [ 0.19567522  0.54273504  0.26158893]\n",
      " [ 0.11802752  0.74406731  0.13790481]\n",
      " [ 0.54570061  0.34431088  0.1099883 ]]\n",
      "Viterbi sequence: [1 1 1 1 0] its probability 0.000408371095546\n",
      "State transition probability:\n",
      "[[[  3.07955146e-02   3.43531743e-02   9.43760946e-02]\n",
      "  [  6.62453920e-02   3.67618322e-01   6.89015239e-02]\n",
      "  [  1.68785802e-04   3.18266422e-01   1.92741342e-02]]\n",
      "\n",
      " [[  2.22395957e-02   9.66233294e-03   6.53077289e-02]\n",
      "  [  1.73219576e-01   3.74381095e-01   1.72636926e-01]\n",
      "  [  2.16084241e-04   1.58691511e-01   2.36442778e-02]]\n",
      "\n",
      " [[  4.83359061e-02   6.01336136e-02   8.72057825e-02]\n",
      "  [  6.95711821e-02   4.30564761e-01   4.25993316e-02]\n",
      "  [  1.20484357e-04   2.53368825e-01   8.09971802e-03]]\n",
      "\n",
      " [[  7.84873813e-02   7.18523795e-03   3.23548727e-02]\n",
      "  [  4.66406941e-01   2.12406784e-01   6.52534440e-02]\n",
      "  [  8.05963005e-04   1.24718860e-01   1.23799695e-02]]]\n"
     ]
    }
   ],
   "source": [
    "print 'Forward probabilities:\\n{}'.format(np.exp(loghmm.forward(O)))\n",
    "print 'Backward probabilities:\\n{}'.format(np.exp(loghmm.backward(O)))\n",
    "print 'Full model probability: {}'.format(np.exp(loghmm.full_prob(O)))\n",
    "print 'Complete state probability:\\n{}'.format(np.exp(loghmm.gamma(O)))\n",
    "seq,vite_prob=loghmm.viterbi(O)\n",
    "print 'Viterbi sequence: {} its probability {}'.format(seq,np.exp(vite_prob))\n",
    "print 'State transition probability:\\n{}'.format(np.exp(loghmm.xi(O)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected values for Baum-Welch are also correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected priors: [ 0.15952486  0.50276518  0.33770928]\n",
      "Expected transitions:\n",
      "[[ 0.31529918  0.19517373  0.48952711]\n",
      " [ 0.30896547  0.55182409  0.13921049]\n",
      " [ 0.00142572  0.92964518  0.06892936]]\n",
      "Expected observations:\n",
      "[[  6.31844342e-01   1.92840993e-01   1.75314546e-01   1.00893489e-43]\n",
      " [  2.96791017e-01   5.13050258e-01   1.90158710e-01   1.00893489e-43]\n",
      " [  4.34766293e-01   3.11200529e-01   2.54033178e-01   1.00893489e-43]]\n"
     ]
    }
   ],
   "source": [
    "exp_pi,exp_a,exp_b=loghmm.exp_values(O)\n",
    "print 'Expected priors: {}'.format(np.exp(exp_pi))\n",
    "print 'Expected transitions:\\n{}'.format(np.exp(exp_a))\n",
    "print 'Expected observations:\\n{}'.format(np.exp(exp_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the Baum-Welch procedure works the same as well. The only exception here is that the *exp_err* value is not retrieved in the log domain, since it's  more convinient this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 P=0.00429750420153 delta_exp=0.0312950797379\n",
      "Iteration #2 P=0.00509988516569 delta_exp=0.0025048465468\n",
      "Iteration #3 P=0.00619260035455 delta_exp=0.00354749895632\n",
      "Iteration #4 P=0.00862175505608 delta_exp=0.00476953713223\n",
      "Iteration #5 P=0.0136389117688 delta_exp=0.00249158591032\n",
      "Iteration #6 P=0.0189214926213 delta_exp=0.00156688096467\n",
      "Iteration #7 P=0.0234132502228 delta_exp=0.00485255988315\n",
      "Iteration #8 P=0.0374569296837 delta_exp=0.00896290969104\n",
      "Iteration #9 P=0.109154902399 delta_exp=0.00389891047962\n",
      "Iteration #10 P=0.218593791127 delta_exp=0.000297478283755\n",
      "Iteration #11 P=0.238835379481 delta_exp=7.89276600699e-05\n",
      "Iteration #12 P=0.244890540838 delta_exp=1.83132779057e-05\n",
      "Iteration #13 P=0.247751682997 delta_exp=3.72287468053e-06\n",
      "Iteration #14 P=0.249030068517 delta_exp=7.08665595539e-07\n",
      "Iteration #15 P=0.249585136771 delta_exp=1.30945835508e-07\n"
     ]
    }
   ],
   "source": [
    "loghmm.setModel(np.log(pi),np.log(a),np.log(b),N,M)\n",
    "for i in range(15):    \n",
    "    prob,exp_err=loghmm.baum_welch(O)\n",
    "    print 'Iteration #{} P={} delta_exp={}'.format(i+1,np.exp(prob),exp_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, gradient descent works similarly to the one above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #1 P=0.00429750420153\n",
      "Iteration #2 P=0.0048121935688\n",
      "Iteration #3 P=0.00581054808572\n",
      "Iteration #4 P=0.0079429903999\n",
      "Iteration #5 P=0.0128070320934\n",
      "Iteration #6 P=0.0240163747221\n",
      "Iteration #7 P=0.0483203493059\n",
      "Iteration #8 P=0.0939218401909\n",
      "Iteration #9 P=0.164299041033\n",
      "Iteration #10 P=0.254913568497\n",
      "Iteration #11 P=0.356227010489\n",
      "Iteration #12 P=0.458135515451\n",
      "Iteration #13 P=0.552913546562\n",
      "Iteration #14 P=0.636195361614\n",
      "Iteration #15 P=0.706535339355\n",
      "Iteration #16 P=0.764397203922\n",
      "Iteration #17 P=0.811213552952\n",
      "Iteration #18 P=0.84873342514\n",
      "Iteration #19 P=0.878661632538\n",
      "Iteration #20 P=0.902498006821\n"
     ]
    }
   ],
   "source": [
    "loghmm.setModel(np.log(pi),np.log(a),np.log(b),N,M)\n",
    "\n",
    "for i in range(20):\n",
    "    prob=loghmm.gradient_descent(O,0.2)\n",
    "    print 'Iteration #{} P={}'.format(i+1,np.exp(prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
